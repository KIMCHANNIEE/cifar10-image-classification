{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로드"
      ],
      "metadata": {
        "id": "kdj1feP5521w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q79aGq09oaTB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 데이터셋에 대한 전처리 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),#이미지를 텐서로 변환\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 각 텐서의 채널을 정규화함\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# CIFAR-10 데이터셋으로부터 클래스 레이블 가져오기\n",
        "class_labels = train_dataset.classes\n",
        "\n",
        "\n",
        "# 이미지와 레이블을 함께 출력하는 함수\n",
        "def imshow(images, labels):\n",
        "    batch_size = images.shape[0]\n",
        "\n",
        "    fig, axarr = plt.subplots(1, batch_size, figsize=(10, 4))\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        img = images[i] / 2 + 0.5  # 언노말라이즈\n",
        "        npimg = img.numpy()\n",
        "        axarr[i].imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        axarr[i].set_title(class_labels[labels[i].item()])\n",
        "        axarr[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# 학습 데이터의 일부를 가져옴\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "images, labels = next(iter(dataloader))\n",
        "\n",
        "# 이미지와 레이블을 함께 출력\n",
        "imshow(images, labels)"
      ],
      "metadata": {
        "id": "DTQQr6T556uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 구성"
      ],
      "metadata": {
        "id": "ucJHE5RS52hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolution layer\n",
        "        self.conv_layer1 = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.maxpooling1 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        self.maxpooling2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = torch.nn.Linear(8*8*64, 10)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.maxpooling1(self.relu1(self.conv_layer1(x)))\n",
        "        out = self.maxpooling2(self.relu2(self.conv_layer2(out)))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "7iRkvYTs5-a4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolution layer\n",
        "        self.conv_layer1 = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.maxpooling1 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        self.maxpooling2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = torch.nn.Linear(8*8*64, 10)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)"
      ],
      "metadata": {
        "id": "XmmWNaIp5_Qz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.conv_layer2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "self.relu2 = torch.nn.ReLU()\n",
        "self.maxpooling2 = torch.nn.MaxPool2d(2)\n",
        "\n",
        "# Fully connected layer\n",
        "self.fc = torch.nn.Linear(8*8*64, 10)"
      ],
      "metadata": {
        "id": "Htt6XmIT6Aoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델의 인스턴스 생성\n",
        "model = CNN()\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "learning_rate = 0.001\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 훈련 루프\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # 옵티마이저 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # outputs 계산\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Loss 계산\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # 옵티마이저 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch {epoch+1}, Batch {i+1}/{len(train_dataloader)}, Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "id": "X9__DoLY6CMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 루프\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "V5T2C6Gx6DnZ",
        "outputId": "66a691b0-bc62-4590-88b5-db9498bf2c2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-1463688308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 테스트 루프\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "cQh3hNJ86FGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 100 * total_correct / total_samples\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "v1qJ6wcG6NAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장하기\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "# 모델 불러오기\n",
        "model = CNN()\n",
        "model.load_state_dict(torch.load('model.pth'))"
      ],
      "metadata": {
        "id": "EoFxzk1t6OpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "model.eval()\n",
        "\n",
        "# 테스트 데이터셋에서 쿼리 이미지 선택\n",
        "query_image_index = 1\n",
        "query_image, query_label = test_dataset[query_image_index]\n",
        "\n",
        "# 쿼리 이미지에 대해 추론 수행\n",
        "with torch.no_grad():\n",
        "    query_image = query_image.unsqueeze(0)\n",
        "    query_features = model(query_image)\n",
        "\n",
        "# 데이터셋 내 다른 이미지들과의 코사인 유사도 계산\n",
        "similarities = []\n",
        "for i in range(len(test_dataset)):\n",
        "    # 데이터셋으로부터 다른 이미지와 해당 레이블 가져오기\n",
        "    image, _ = test_dataset[i]\n",
        "\n",
        "    # 이미지 텐서에 배치 차원 추가\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    # 모델을 통과하여 특성 추출\n",
        "    features = model(image)\n",
        "\n",
        "    # 쿼리 이미지와의 코사인 유사도 계산\n",
        "    similarity = cosine_similarity(query_features.detach().numpy(), features.detach().numpy())\n",
        "\n",
        "    # 코사인 유사도와 해당 이미지 인덱스를 similarities 리스트에 저장\n",
        "    similarities.append((i, similarity.item()))"
      ],
      "metadata": {
        "id": "kq8zgOhf6P3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사도 값 내림차순 정렬\n",
        "similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 K개의 이미지 시각화\n",
        "top_k = 5\n",
        "fig, axes = plt.subplots(1, top_k, figsize=(6, 3))\n",
        "\n",
        "for i, (image_index, similarity) in enumerate(similarities[:top_k]):\n",
        "    image, _ = test_dataset[image_index]\n",
        "\n",
        "    # 넘파이로 변환\n",
        "    image_np = image.permute(1, 2, 0).detach().numpy()\n",
        "\n",
        "    # 이미지 픽셀값 [0, 1]로 스케일링\n",
        "    image_np = (image_np - np.min(image_np)) / (np.max(image_np) - np.min(image_np))\n",
        "\n",
        "\t\t# imshow를 위해서 RGB data ([0..1] for floats or [0..255] for integers) 사이의 값으로 정의해야 합니다.\n",
        "\n",
        "    # subplot으로 시각화\n",
        "    axes[i].imshow(image_np)\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f'Similarity: {similarity:.4f}', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eV2_Pd-I6Q31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}